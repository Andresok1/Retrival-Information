{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Text classification Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes inferencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider you are building a system that can decide the author given the snippet of a book. Assume you simplify the problem so that the \"documents\" are represented by their key words (in other words, stop words are removed plus other preprocessing steps). You have annotated some of the training data as follows:\n",
    "\n",
    "| doc_id | Document | label |\n",
    "| --- | --- | --- |\n",
    "| 1 | dialectic dasein dialectic | Hegel |\n",
    "| 2 | dialectic analysis ideology | Hegel |\n",
    "| 3 | utopia justice analysis | Plato |\n",
    "| 4 | Lacanian analysis ideology | Zizek |\n",
    "| 5 | justice Marx dialectic ideology | Zizek |\n",
    "\n",
    "Now you are faced with the following sentence:\n",
    "\n",
    "q = ```a dialectic analysis of ideology```\n",
    "\n",
    "What is the expected prediction of your system? Please ignore out-of-vocabulary terms while prediction, and use Add-1 (Laplace) smoothing for computing the likelihood probabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer goes here:\n",
    "##### vocabularies:\n",
    "\n",
    "analysis, dasein, dialectic, \n",
    "ideology, justice, Lacanian,\n",
    "Marx, utopia\n",
    "\n",
    "##### priors:\n",
    "\n",
    "P(Hegel) = 2/5\n",
    "\n",
    "P(Plato) = 1/5\n",
    "\n",
    "P(Zizek) = 2/5\n",
    "\n",
    "##### Calculating Likelihoods: $P(w|c)$:\n",
    "\n",
    "\n",
    "The formula for Multinomial Naive Bayes with Add-1 (Laplace) smoothing is:$$P(w|c) = \\frac{\\text{count}(w, c) + 1}{\\text{count}(\\text{all words in } c) + |V|}$$\n",
    "\n",
    "P(dialectic|Hegel) = (3 + 1) / (6 + 8) = 2/7\n",
    "\n",
    "P(analysis|Hegel) = P(ideology|Hegel) = (1 + 1) / (6 + 8) = 1/7\n",
    "\n",
    "P(dialectic|Plato) = P(ideology|Plato) = (0 + 1) / (3 + 8) = 1/11\n",
    "\n",
    "P(analysis|Plato) = (1 + 1) / (3 + 8) = 2/11\n",
    "\n",
    "P(dialectic|Zizek) = P(analysis|Zizek) = (1 + 1) / (7 + 8) = 2/15\n",
    "\n",
    "P(ideology) = (2 + 1) / (7 + 8) = 1/5\n",
    "\n",
    "\n",
    "Example Calculation for P(dialectic|Hegel): \n",
    "\n",
    "Words in Hegel's docs: dialectic (3), dasein (1), analysis (1), ideology (1).\n",
    "Total raw word count ($N_{Hegel}$) = 6. Denominator = $6 + 8 = \\mathbf{14}$. \n",
    "\n",
    "\"dialectic\" appears 3 times in Hegel docs.$ \n",
    "\n",
    "P = (3 + 1) / 14 = \\mathbf{2/7}$\n",
    "\n",
    "\n",
    "\n",
    "##### Calculating Inference: $P(c|q)$:\n",
    "\n",
    "Filter: We remove \"a\" and \"of\" because they are not in our vocabulary $V$. We strictly ignore terms we've never seen before.\n",
    "\n",
    "Formula: $P(c|q) \\propto P(c) \\times \\prod P(w_i|c)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$\\hat{P}(Hegel|q) \\propto 2/5 * 2/7 * 1/7 * 1/7 \\approx 0.00233$\n",
    "\n",
    "$\\hat{P}(Plato|q) \\propto 1/5 * 1/11 * 1/11 * 2/11 \\approx 0.00030$\n",
    "\n",
    "$\\hat{P}(Zizek|q) \\propto 2/5 * 2/15 * 2/15 * 1/5 \\approx 0.00142$\n",
    "\n",
    "$\\hat{P}(Hegel|q)$ is the highest among the three authors, therefore the system should predict \"Hegel\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro/Micro measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider one of your models uses a 1-vs-rest strategy* to do the multi-class classification. The results shows as follows:\n",
    "\n",
    "class name = Hegel\n",
    "\n",
    "| | in the class | not in the class |\n",
    "| --- | --- | --- |\n",
    "| predict to be in the class | 20 | 10 |\n",
    "| predicted to not be in the class |  10 | 60 |\n",
    "\n",
    "class name = Plato\n",
    "\n",
    "|| in the class | not in the class |\n",
    "| --- | --- | --- |\n",
    "| predicted to be in the class | 15 | 5 |\n",
    "| predicted to not be in the class | 15 | 65 |\n",
    "\n",
    "class name = Zizek\n",
    "\n",
    "|| in the class | not in the class |\n",
    "| --- | --- | --- |\n",
    "| predicted to be in the class | 40 | 10 |\n",
    "| predicted to not be in the class | 0 | 50 |\n",
    "\n",
    "1. Calculate the counts of instances in these three classes respectively.\n",
    "2. Calculate the precision/recall for the three classes\n",
    "3. Calculate the micro and macro F1 of this model\n",
    "\n",
    "*1-vs-all strategy means a multi-class classification strategy, where we transfer the multi-class classification into a binary classification. Its two classes are \"to be this class\" and \"to be the rest classes\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer goes here:\n",
    "\n",
    "1.Since we use 1-vs-all strategy, for each class, all \"in the classes\" sum up to the counts of the instance under this class. Therefore:\n",
    "\n",
    "#Hegel = 20 + 10 = 30\n",
    "#Plato = 15 + 15 = 30\n",
    "#Zizek = 40 + 0  = 40\n",
    "\n",
    "2.The precision/recall for class Hegel:\n",
    "\n",
    "TP (Top-Left): 20 (We predicted Hegel, and it was Hegel).\n",
    "\n",
    "FP (Top-Right): 10 (We predicted Hegel, but it wasn't).\n",
    "\n",
    "FN (Bottom-Left): 10 (We predicted \"Not Hegel\", but it actually was Hegel).\n",
    "\n",
    "TN (Bottom-Right): 15 (We predicted \"Not Hegel\", and it wasn't).\n",
    "\n",
    "Total Hegel Instances: This is the sum of the first column (Actual: Yes).\n",
    "\n",
    "$TP + FN = 20 + 10 = \\mathbf{30}$.\n",
    "\n",
    "Precision (P): \"When we predict Hegel, how often are we right?\"\n",
    "\n",
    "Formula: $TP / (TP + FP)$Math: $20 / (20 + 10) = 20/30 = \\mathbf{2/3}$.\n",
    "\n",
    "Recall (R): \"Out of all real Hegel texts, how many did we find?\"\n",
    "\n",
    "Formula: $TP / (TP + FN)$Math: $20 / (20 + 10) = 20/30 = \\mathbf{2/3}$.\n",
    "\n",
    "for class Plato:\n",
    "\n",
    "P = 3/4\n",
    "\n",
    "R = 1/2\n",
    "\n",
    "for class Zizek:\n",
    "\n",
    "P = 4/5\n",
    "\n",
    "R = 1\n",
    "\n",
    "3.For the micro F1 we need to calculate the pooled table:\n",
    "\n",
    "| | in the class | not in the class |\n",
    "| --- | --- | --- |\n",
    "| predicted to be in the class | 75 | 25 |\n",
    "| predicted to not be in the class | 25 | 175 |\n",
    "\n",
    "\n",
    "Recall F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "micro precision = 75 / (75 + 25) = 0.75\n",
    "\n",
    "micro recall = 75 / (75 + 25) = 0.75\n",
    "\n",
    "micro f1 = 2 / (1/0.75 + 1/0.75) = 0.75\n",
    "\n",
    "The Meaning: \"If you feed a random document into this system, there is a good chance it will be correct.\"\n",
    "\n",
    "The macro F1 is the average of the individual F1 scores for each class.\n",
    "\n",
    "f1 Hegel = 2/3\n",
    "\n",
    "f1 Plato =  2/(4/3 + 2) = 0.6\n",
    "\n",
    "f1 Zizek = 2/(5/4 + 1) = 8/9\n",
    "\n",
    "macro f1 = (2/3 + 0.6 + 8/9)/3 = 0.719\n",
    "\n",
    "The Meaning: \"The system is robust, but it has a specific weak spot.\" \n",
    "In our specific case, the system is good at identifying Hegel and Zizek, but struggles with Plato. If it were better, it would have a higher F1 score for Plato and thus a higher macro F1.\n",
    "\n",
    "\n",
    "Macro averaging treats every Class (Author) as equally important, regardless of how many documents they have. You calculate the F1 score for each author individually, then take the simple average.\n",
    "\n",
    "Micro averaging treats every Instance (Document) as equally important. You don't calculate separate F1 scores first. Instead, you throw all the predictions into one big pile (pool them) and calculate a single global F1. \n",
    "\n",
    "\n",
    "In text classification tasks (like predicting authors or sentiment), here is a rough guide for F1 scores:\n",
    "\n",
    "0.90+ (Excellent): This is near-human performance. Usually required for medical or legal automation.\n",
    "\n",
    "0.80 - 0.90 (Good): This is a solid \"production-ready\" model for most business apps.\n",
    "\n",
    "0.70 - 0.80 (Acceptable): This is typical for a first prototype or a difficult task (like discerning 3 distinct philosophers). It makes mistakes, but is generally useful.\n",
    "\n",
    "< 0.60 (Poor): The model is struggling. It might be slightly better than random, but not reliable enough to use.\n",
    "\n",
    "Because Micro F1 is often \"easier\" to get high (it rides the wave of the majority class), we typically hold it to a higher standard than Macro F1 (for example, shifting the threshold by 0.05)\n",
    "\n",
    "Rather than just looking at the raw numbers, data scientists also look at the gap between the two.$$\\text{Gap} = \\text{Micro F1} - \\text{Macro F1}$$\n",
    "\n",
    "Small Gap (< 0.05): Excellent. Your model is fair. It treats rare classes almost as well as common ones.\n",
    "\n",
    "Large Gap (> 0.10): Your model is just overfitting to the majority class.\n",
    "\n",
    "As we can see, the micro f1 is biased by the larger class (Zizek) and becomes better than the macro F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector space Classification\n",
    "\n",
    "1. What are two premises of vector space classification?\n",
    "2. Why do we need those?\n",
    "3. Do they hold in practice?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Documents in the same class form a contiguous region and regions of different classes do not overlap.\n",
    "\n",
    "Contiguity: We assume that documents belonging to the same class (e.g., \"Hegel\") are statistically similar to each other. In vector space, this means they cluster together to form a single, solid \"cloud\" or region. They aren't scattered randomly across the universe; they hang out in the same neighborhood.\n",
    "\n",
    "Separability: We assume that the cloud for \"Hegel\" does not merge or mix with the cloud for \"Plato.\" There is a clear boundary or gap between them.\n",
    "\n",
    "2. To be able to separate the classes, find a boundary. We need these assumptions because most basic vector space classifiers (like Rocchio, kNN, and Linear SVMs) rely on linear decision boundaries.\n",
    "\n",
    "3. If you choose your representation well.\n",
    "Strictly speaking? No. In the real world, classes are messy. The word \"Bank\" appears in both \"Finance\" documents and \"Nature\" (river bank) documents. This creates overlap. However the answer is \"Yes\" IF we engineer our features correctly. While classes might overlap in 1 or 2 dimensions, they often separate cleanly when you look at 10,000 dimensions (words)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
